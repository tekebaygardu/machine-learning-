{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3703,"status":"ok","timestamp":1734547828157,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"M1B3YNPZnNEu","outputId":"3f4afc62-65ab-4368-f789-b5f663ebc178"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized data saved to '/content/1s.csv'.\n"]}],"source":["import pandas as pd\n","from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Load the data from the specified CSV file\n","input_file_path = '/content/critical  labae encodee.xlsx'\n","df = pd.read_excel(input_file_path)\n","\n","# Ensure \"description\" column exists\n","if 'description' not in df.columns:\n","    raise ValueError(\"The 'description' column is missing from the CSV file.\")\n","\n","# Tokenize the descriptions and create input IDs and attention masks\n","tokenized_data = tokenizer(\n","    df['description'].tolist(),\n","    padding=True,\n","    truncation=True,\n","    return_tensors='np'  # Use 'pt' for PyTorch tensors if needed\n",")\n","\n","# Add input IDs and attention masks to the DataFrame\n","df['input_ids'] = tokenized_data['input_ids'].tolist()\n","df['attention_mask'] = tokenized_data['attention_mask'].tolist()\n","\n","# Save the DataFrame to a new CSV file\n","output_file_path = '/content/1s.csv'\n","df.to_csv(output_file_path, index=False)\n","\n","print(f\"Tokenized data saved to '{output_file_path}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1734547869506,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"F4EAIxwz3sJt","outputId":"5c503d15-bd3f-43c3-d54a-ea0994c0cd8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                         description  severity \n","0  Improper Input Validation vulnerability in the...          3\n","1  Improper input validation in some Intel(R) Neu...          3\n","2  This package provides universal methods to use...          3\n","3  Zabbix server can perform command execution fo...          3\n","4  Discord-Recon is a Discord bot created to auto...          3\n","Modified data saved to: /content/1.csv\n"]}],"source":["import pandas as pd\n","\n","# Load the dataset\n","data_path = '/content/critical  labae encodee.xlsx'\n","data = pd.read_excel(data_path)\n","\n","# Display the first few rows to check the data\n","print(data.head())\n","\n","# Lowercase the 'description' column\n","data['description'] = data['description'].str.lower()\n","\n","# Save the modified DataFrame to a new CSV file\n","output_path = '/content/1.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f'Modified data saved to: {output_path}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23318,"status":"ok","timestamp":1734550274921,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"U7Jyb5uTtNGB","outputId":"91f4d8cb-01b9-40db-94e2-26369d5b04d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                         description  severity \n","0  improper input validation vulnerability in the...          3\n","1  improper input validation in some intel(r) neu...          3\n","2  this package provides universal methods to use...          3\n","3  zabbix server can perform command execution fo...          3\n","4  discord-recon is a discord bot created to auto...          3\n","Modified data saved to: /content/2.csv\n"]}],"source":["import pandas as pd\n","import spacy\n","\n","# Load the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Load the dataset\n","data_path = '/content/1.csv'\n","data = pd.read_csv(data_path)\n","\n","# Display the first few rows to check the data\n","print(data.head())\n","\n","# Define a function to remove stop words\n","def remove_stopwords(text):\n","    doc = nlp(text)\n","    filtered_text = ' '.join(token.text for token in doc if not token.is_stop)\n","    return filtered_text\n","\n","# Apply the function to the 'description' column\n","data['description'] = data['description'].apply(remove_stopwords)\n","\n","# Save the modified DataFrame to a new CSV file\n","output_path = '/content/2.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f'Modified data saved to: {output_path}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14803,"status":"ok","timestamp":1734550336467,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"uC9wgWWh3t1O","outputId":"787e8f49-504c-4078-ceae-7081ce37c9c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                         description  severity \n","0  improper input validation vulnerability upload...          3\n","1  improper input validation intel(r ) neural com...          3\n","2  package provides universal methods use multipl...          3\n","3  zabbix server perform command execution config...          3\n","4  discord - recon discord bot created automate b...          3\n","Modified data saved to: /content/3.csv\n"]}],"source":["import pandas as pd\n","import spacy\n","\n","# Load the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Load the dataset\n","data_path = '/content/2.csv'\n","data = pd.read_csv(data_path)\n","\n","# Display the first few rows to check the data\n","print(data.head())\n","\n","# Define a function to lemmatize text\n","def lemmatize_text(text):\n","    doc = nlp(text)\n","    lemmatized_text = ' '.join(token.lemma_ for token in doc)\n","    return lemmatized_text\n","\n","# Apply the function to the 'description' column\n","data['description'] = data['description'].apply(lemmatize_text)\n","\n","# Save the modified DataFrame to a new CSV file\n","output_path = '/content/3.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f'Modified data saved to: {output_path}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14138,"status":"ok","timestamp":1734550393948,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"0DfpH8nIEyDo","outputId":"9837c144-c216-48df-eb7d-f463a38c9e28"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                         description  severity \n","0  improper input validation vulnerability upload...          3\n","1  improper input validation intel(r ) neural com...          3\n","2  package provide universal method use multiple ...          3\n","3  zabbix server perform command execution config...          3\n","4  discord - recon discord bot create automate bu...          3\n","Modified data saved to: /content/num$4.csv\n"]}],"source":["import pandas as pd\n","import spacy\n","\n","# Load the spaCy English model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Load the dataset\n","data_path = '/content/3.csv'\n","data = pd.read_csv(data_path)\n","\n","# Display the first few rows to check the data\n","print(data.head())\n","\n","# Define a function to tokenize text\n","def tokenize_text(text):\n","    doc = nlp(text)\n","    tokens = [token.text for token in doc]  # Extract tokens\n","    return ' '.join(tokens)  # Join tokens back into a string if needed\n","\n","# Apply the function to the 'description' column\n","data['description'] = data['description'].apply(tokenize_text)\n","\n","# Save the modified DataFrame to a new CSV file\n","output_path = '/content/num$4.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f'Modified data saved to: {output_path}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18033,"status":"ok","timestamp":1734550489408,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"DKPsmYy7HF3B","outputId":"efa29ef8-9a80-4941-9498-54da99634079"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized data saved to /content/4.csv\n"]}],"source":["import pandas as pd\n","import spacy\n","\n","# Load spaCy model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Load the CSV file\n","file_path = '/content/3.csv'\n","data = pd.read_csv(file_path)\n","\n","# Tokenize the 'description' column using spaCy\n","data['description'] = data['description'].apply(lambda x: [token.text for token in nlp(x)])\n","\n","# Save the modified DataFrame back to a CSV file\n","output_path = '/content/4.csv'\n","data.to_csv(output_path, index=False)\n","\n","print(f\"Tokenized data saved to {output_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9815,"status":"ok","timestamp":1730540344757,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"b7zTQDEYx3wB","outputId":"3c6c935a-bbb3-4318-d20c-6e43fe2c1ad7"},"outputs":[{"name":"stdout","output_type":"stream","text":["description\n","\n","\"(0, 446)0.08774108373334055 (0, 617)0.1349129069352227 (0, 750)0.17450338662545228 (0, 1863)0.08783849655790449 (0, 2045)0.22416695494608804 (0, 3675)0.26364737202916333 (0, 3880)0.2426597666067508 (0, 4576)0.2975768640590574 (0, 4821)0.3194525240773637 (0, 5235)0.3323119822946025 (0, 5273)0.23464207906805085 (0, 6188)0.31468165089018885 (0, 6634)0.12454124739475962 (0, 7027)0.3460277180692651 (0, 8315)0.20031983231494463 (0, 8382)0.10941387967275404 (0, 8495)0.20145177960315394 (0, 8624)0.09468087852617457 (0, 8693)0.184227942578642 (0, 9138)0.17703527553651446\"\n","\n","\"(1, 153)0.36948545809062794 (1, 715)0.15907484616272488 (1, 750)0.20936628419154552 (1, 1637)0.25375951154333476 (1, 1863)0.10538717894783813 (1, 1916)0.07494095117789706 (1, 2474)0.2999104351516545 (1, 3100)0.11646949043219784 (1, 3716)0.2696594182555352 (1, 4385)0.20279825755413514 (1, 4467)0.23395524970684467 (1, 4700)0.26619790563151374 (1, 6285)0.29054266587638655 (1, 6634)0.1494225338536649 (1, 6672)0.0998510604090275 (1, 6713)0.34662251357770407 (1, 8315)0.24034042979161427 (1, 8382)0.13127296764293392 (1, 8495)0.2416985214723319\"\n","\n","\"(2, 446)0.06849044194727898 (2, 617)0.10531263379955656 (2, 750)0.13621685033658382 (2, 753)0.11297032270201554 (2, 1666)0.4254767594308202 (2, 1805)0.7447947450246711 (2, 1863)0.06856648212277981 (2, 1916)0.04875770886463037 (2, 3100)0.07577680049222332 (2, 3299)0.22614688719859832 (2, 3583)0.12080501897476507 (2, 3716)0.17544446929553806 (2, 5033)0.16982694505271242 (2, 5710)0.13416060951458475 (2, 6634)0.09721654567951547 (2, 6672)0.12992920043651357 (2, 8382)0.17081633039154662 (2, 8624)0.07390762614606516\"\n","\n","\"(3, 446)0.06128621905206919 (3, 617)0.09423523867692585 (3, 750)0.1218887700379697 (3, 753)0.10108744733795268 (3, 1666)0.19036132005188314 (3, 1805)0.8886038712291776 (3, 1863)0.06135426087980465 (3, 1916)0.043629089563401016 (3, 2045)0.15657824727597788 (3, 3100)0.06780615604154158 (3, 3583)0.10809804470492199 (3, 3716)0.15699019996099683 (3, 6634)0.08699074417692497 (3, 6672)0.11626249171149826 (3, 8333)0.12845131421662837 (3, 8382)0.15284887561545155 (3, 8624)0.06613359232070391\"\n","\n","\"(4, 446)0.14858583557582886 (4, 715)0.05613232766636781 (4, 717)0.03728548268254225 (4, 750)0.07387853673928962 (4, 1329)0.06619660503451057 (4, 1916)0.02644421873489576 (4, 1956)0.1296622940469354 (4, 2810)0.07022153407537755 (4, 3307)0.13295083513573802 (4, 4092)0.10007793656577234 (4, 4900)0.3855481187601958 (4, 5521)0.12742572273418745 (4, 5801)0.12638613703303633 (4, 6105)0.17323620911281848 (4, 6175)0.1276395718550118 (4, 6187)0.12407230699997764 (4, 6672)0.10570255277783526 (4, 6806)0.37445183421082345 (4, 6869)0.10090688128565595 (4, 7060)0.12659022121484076 (4, 7133)0.09540653017482877 (4, 7544)0.11440896967739138 (4, 7582)0.3810122026032913 (4, 7583)0.13037937362067395 (4, 7816)0.5329001426515638 (4, 8013)0.07511371552592219 (4, 8333)0.07785618916005993 (4, 8382)0.04632195102632337 (4, 8460)0.10519008509954456\"\n","\n","\"(5, 137)0.2975723238660512 (5, 446)0.0629637151168774 (5, 717)0.06319936218740774 (5, 1234)0.6802953735349683 (5, 1486)0.1707095290465628 (5, 1856)0.1456179976684345 (5, 1916)0.04482328341620811 (5, 3100)0.06966211259570294 (5, 4056)0.20482162323651476 (5, 4603)0.21671665915977487 (5, 5553)0.48668324122274886 (5, 5608)0.19578281903849437 (5, 6672)0.059722385555239614 (5, 7297)0.12572106520837353\"\n","\n","\"(6, 676)0.39762558113930485 (6, 970)0.37650168500045456 (6, 1649)0.2611860322507337 (6, 1916)0.07534206676805001 (6, 5142)0.22527666990809853 (6, 6291)0.2407325925855727 (6, 6732)0.4077890542818348 (6, 7969)0.35454607625319823 (6, 8013)0.2140060414370435 (6, 8448)0.3907089857725089 (6, 8521)0.16461202415462914\"\n","\n","\"(7, 446)0.06999580282765525 (7, 515)0.26811228807790244 (7, 717)0.0702577680858224 (7, 1282)0.2381518828798114 (7, 1649)0.17274191856689333 (7, 1863)0.07007351430067266 (7, 1916)0.049829361279986197 (7, 2028)0.2056525575465463 (7, 2276)0.2151374688080454 (7, 2622)0.19305478627656056 (7, 3100)0.0774423092531228 (7, 4134)0.5041826681936665 (7, 6634)0.09935328156017902 (7, 6672)0.06639246613644031 (7, 6697)0.23379188745647833 (7, 7127)0.15956838370460633 (7, 7402)0.20460414631114235 (7, 8521)0.544351407818642 (7, 8624)0.0755320520659242\"\n","\n","\"(8, 368)0.48483354498592435 (8, 1856)0.28923755109558236 (8, 1916)0.08903141737250782 (8, 2130)0.2683797943473927 (8, 3100)0.13836819056669053 (8, 3863)0.3111432685935711 (8, 4417)0.258471064688793 (8, 4707)0.25685457692294394 (8, 5086)0.4833436494953344 (8, 6672)0.11862514812843185 (8, 7297)0.2497167493320121 (8, 8382)0.15595503110444678 (8, 8624)0.13495508430657435\"\n","\n"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Load your dataset\n","data = pd.read_csv('/content/4.csv')\n","\n","# Separate the textual value\n","x = data['description'].values\n","\n","# Convert textual data into feature vector\n","vectorizer = TfidfVectorizer()\n","vectorizer.fit(x)\n","x_transformed = vectorizer.transform(x)\n","\n","# Save the encoded data with all values of one row in a single cell\n","with open('/content/aug+pre tfi.csv', 'w') as f:\n","    f.write(\"description\\n\")  # Column header\n","    for i in range(x_transformed.shape[0]):\n","        row_data = \" \".join([f\"({i}, {idx}){value}\" for idx, value in zip(x_transformed[i].indices, x_transformed[i].data)])\n","        f.write(f'\"{row_data}\"\\n')  # Add quotes to ensure single cell\n","\n","# Display the first few lines of the saved file\n","with open('/content/aug+pre tfi.csv') as f:\n","    for _ in range(10):\n","        print(f.readline())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1751106410158,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"B3Ka1Ddqmz9i"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"elapsed":745463,"status":"error","timestamp":1732795655944,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"SovQClRjm3U3","outputId":"2dcbf512-3a8c-4740-8613-b758a28c97fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X: (1970, 199)\n","Shape of y: (1970,)\n","Cross-validation accuracy scores: [0.84130435 0.82826087 0.83006536]\n","Mean cross-validation accuracy: 0.8332101922894762\n"]},{"ename":"AxisError","evalue":"axis 1 is out of bounds for array of dimension 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5b047f93bfb4>\u001b[0m in \u001b[0;36m<cell line: 79>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Predict on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0my_pred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Calculate evaluation metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \"\"\"\n\u001b[1;32m   1228\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'keepdims'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6316,"status":"ok","timestamp":1732794673813,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"pKbjVaxOnApR","outputId":"baa1a6bf-27a4-44af-d883-c7436a301e6b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikeras\n","  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n","Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n","Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.13.0\n"]}],"source":["pip install scikeras\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":348492,"status":"ok","timestamp":1732976830793,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"eGAqiMSx2O4l","outputId":"ada73e4b-e440-4507-a295-28009258f3d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X: (7154, 1064)\n","Shape of y: (7154,)\n","Cross-validation accuracy scores: [0.63273453 0.61676647 0.62037962 0.63836164 0.61838162]\n","Mean cross-validation accuracy: 0.6253247750253739\n","Accuracy: 0.68\n","F1 Score: 0.68\n","Precision: 0.69\n","Recall: 0.68\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.96      0.77      0.86       239\n","           1       0.55      0.54      0.54       306\n","           2       0.65      0.74      0.69       434\n","           3       0.69      0.62      0.65        95\n","\n","    accuracy                           0.68      1074\n","   macro avg       0.71      0.67      0.69      1074\n","weighted avg       0.69      0.68      0.68      1074\n","\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6435,"status":"ok","timestamp":1732976476717,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"dbIAuDsoYOeU","outputId":"42ef425d-acad-4eda-ba57-8b8f33dbf428"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting scikeras\n","  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.5.0)\n","Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.13.1)\n","Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n","Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.13.0\n"]}],"source":["pip install scikeras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18918,"status":"ok","timestamp":1732977063588,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"rlHV2gJZeyIi","outputId":"052479a7-5b3b-4312-cfac-04e3e5253168"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X: (7154, 1064)\n","Shape of y: (7154,)\n","Cross-validation accuracy scores: [0.71357285 0.70159681 0.7002997  0.72327672 0.6973027 ]\n","Mean cross-validation accuracy: 0.7072097563115527\n","Accuracy: 0.70\n","F1 Score: 0.70\n","Precision: 0.71\n","Recall: 0.70\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.86      0.82      0.84       239\n","           1       0.61      0.55      0.57       306\n","           2       0.68      0.79      0.73       434\n","           3       0.76      0.54      0.63        95\n","\n","    accuracy                           0.70      1074\n","   macro avg       0.73      0.67      0.69      1074\n","weighted avg       0.71      0.70      0.70      1074\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from sklearn.ensemble import RandomForestClassifier\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Load the dataset from an Excel file\n","file_path = '/content/mixed.xlsx'\n","data = pd.read_excel(file_path)\n","\n","# Fill missing values in 'description' field with an empty string\n","data['description'] = data['description'].fillna('')\n","\n","# Tokenize the text data\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(data['description'])\n","X = tokenizer.texts_to_sequences(data['description'])\n","X = pad_sequences(X, padding='post')\n","\n","# Print the shape to verify\n","print(\"Shape of X:\", X.shape)\n","print(\"Shape of y:\", data['severity'].shape)\n","\n","# Encode the target variable\n","y = data['severity']\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Stratified sampling for train, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n","\n","# Define the Random Forest model\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Perform 5-fold cross-validation\n","cv = StratifiedKFold(n_splits=5)\n","cv_results = cross_val_score(rf_model, X_train, y_train, cv=cv, scoring='accuracy')\n","\n","# Print cross-validation results\n","print(f\"Cross-validation accuracy scores: {cv_results}\")\n","print(f\"Mean cross-validation accuracy: {np.mean(cv_results)}\")\n","\n","# Fit the model on the entire training set\n","rf_model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = rf_model.predict(X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","\n","# Print the classification report\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412801,"status":"ok","timestamp":1732978703514,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"Y4iYzhpWgO8i","outputId":"a86ca673-9744-462b-b71a-53b5c411bcfe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X: (7154, 1000)\n","Shape of y: (7154,)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n","  _data = np.array(data, dtype=dtype, copy=copy,\n"]},{"name":"stdout","output_type":"stream","text":["Cross-validation accuracy scores: [0.79041916 0.78642715 0.76523477 0.77122877 0.77622378]\n","Mean cross-validation accuracy: 0.7779067240145084\n","Accuracy: 0.80\n","F1 Score: 0.79\n","Precision: 0.80\n","Recall: 0.80\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.94      0.85      0.89       239\n","           1       0.74      0.64      0.68       306\n","           2       0.75      0.88      0.81       434\n","           3       0.87      0.78      0.82        95\n","\n","    accuracy                           0.80      1074\n","   macro avg       0.82      0.79      0.80      1074\n","weighted avg       0.80      0.80      0.79      1074\n","\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Load the dataset from an Excel file\n","file_path = '/content/mixed.xlsx'\n","data = pd.read_excel(file_path)\n","\n","# Fill missing values in 'description' field with an empty string\n","data['description'] = data['description'].fillna('')\n","\n","# Convert text to TF-IDF features\n","tfidf = TfidfVectorizer(max_features=1000)\n","X = tfidf.fit_transform(data['description']).toarray()\n","\n","# Print the shape to verify\n","print(\"Shape of X:\", X.shape)\n","print(\"Shape of y:\", data['severity'].shape)\n","\n","# Encode the target variable\n","y = data['severity']\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","# Stratified sampling for train, validation, and test sets\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n","\n","# Define the Random Forest model with hyperparameter tuning\n","rf_model = RandomForestClassifier(random_state=42)\n","\n","# Hyperparameter tuning using GridSearchCV\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","best_rf_model = grid_search.best_estimator_\n","\n","# Perform 5-fold cross-validation\n","cv = StratifiedKFold(n_splits=5)\n","cv_results = cross_val_score(best_rf_model, X_train, y_train, cv=cv, scoring='accuracy')\n","\n","# Print cross-validation results\n","print(f\"Cross-validation accuracy scores: {cv_results}\")\n","print(f\"Mean cross-validation accuracy: {np.mean(cv_results)}\")\n","\n","# Fit the model on the entire training set\n","best_rf_model.fit(X_train, y_train)\n","\n","# Predict on the test set\n","y_pred = best_rf_model.predict(X_test)\n","\n","# Calculate evaluation metrics\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","\n","# Print the classification report\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"elapsed":31044,"status":"error","timestamp":1733040527958,"user":{"displayName":"Shambel Gashaw","userId":"10044554980528052762"},"user_tz":-180},"id":"q-eH79XlmMTg","outputId":"b2a704b7-e3b5-4681-e88c-6b5952c78527"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data has been successfully saved to /content/mixed.csv\n"]}],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"XbuvG7QK-t8K"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"11fOcCJOFBqbHEyd2XZVFAFLND3J67b1o","authorship_tag":"ABX9TyMMddbMeBOZhEIhVaVEX5px"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}